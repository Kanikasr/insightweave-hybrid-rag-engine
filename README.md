# ğŸ§  InsightWeave â€” Hybrid RAG Search Engine

**InsightWeave** is a hybrid Retrieval-Augmented Generation (RAG) system that combines  
**semantic search over private documents** with **real-time web search** to deliver  
grounded, explainable, and up-to-date answers.

The system is designed to be **model-agnostic**, **cost-efficient**, and **enterprise-ready**,  
demonstrating how modern AI copilots blend internal knowledge bases with live external data.

---

## ğŸš€ Key Features

- ğŸ“„ **Multi-Document Semantic Search** (PDF / Text / Wikipedia)
- ğŸ” **FAISS Vector Database** for fast similarity search
- ğŸŒ **Real-Time Web Search** using Tavily
- ğŸ”€ **Hybrid Query Routing** (Document / Web / Hybrid)
- ğŸ§  **Retrieval-Augmented Generation (RAG)**
- ğŸ§¾ **Citation-Aware Answers**
- ğŸ” **Transparent Evidence Display**
- ğŸ’» **Interactive Streamlit UI**
- ğŸ’° **No Paid APIs Required** (Local Embeddings + Local LLM)

---

## ğŸ—ï¸ System Architecture

```
User Query
   â”‚
   â–¼
Query Router
(doc / web / hybrid)
   â”‚
   â”œâ”€â”€â–º FAISS Vector Search (Documents)
   â”‚
   â”œâ”€â”€â–º Tavily Web Search (Live Data)
   â”‚
   â–¼
Context Assembly
   â”‚
   â–¼
Context Sanitization
(remove source tags)
   â”‚
   â–¼
Local LLM (Flan-T5)
   â”‚
   â–¼
Answer Generation
   â”‚
   â–¼
Deterministic Source Attribution
   â”‚
   â–¼
Streamlit UI Output
```

---

## ğŸ§  Why Hybrid RAG?

Traditional LLMs rely solely on parametric memory, which:
- Becomes outdated
- Hallucinates facts
- Cannot access private data

InsightWeave solves this by:
- Retrieving **relevant documents at query time**
- Augmenting the prompt with **grounded context**
- Combining **private knowledge + live web data**
- Explicitly exposing **evidence used**

---

## ğŸ§° Tech Stack

| Component | Technology |
|--------|-----------|
| Language | Python |
| Orchestration | LangChain |
| Vector Store | FAISS |
| Embeddings | HuggingFace (Sentence Transformers) |
| LLM | Flan-T5 (Local) |
| Web Search | Tavily |
| UI | Streamlit |

---

## ğŸ“‚ Project Structure

    insightweave_hybrid_rag/
    â”‚
    â”œâ”€â”€ app.py                # Streamlit UI
    â”œâ”€â”€ ingestion.py          # Document loading & indexing
    â”œâ”€â”€ rag_pipeline.py       # Hybrid RAG logic
    â”œâ”€â”€ build_index.py        # FAISS index builder
    â”œâ”€â”€ schemas.py            # Data models
    â”œâ”€â”€ utils.py              # Environment loader
    â”‚
    â”œâ”€â”€ data/
    â”‚   â””â”€â”€ docs/             # Input documents
    â”‚
    â”œâ”€â”€ faiss_index/          # Vector index (local)
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ .env                  # API keys (ignored)
    â”œâ”€â”€ .gitignore
    â””â”€â”€ README.md

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/Kanikasr/insightweave-hybrid-rag-engine.git
cd insightweave_hybrid_rag
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate
``` 
### 3ï¸âƒ£ Install Dependencies 
```bash
pip install -r requirements.txt
```
### 4ï¸âƒ£ Add Environment Variables
```bash
TAVILY_API_KEY=your_tavily_key_here
```
## ğŸ“¥ Build Document Index

Add documents to:

    data/docs/

Then run:

    python build_index.py

This creates a local FAISS vector index.

---

## ğŸ–¥ï¸ Run the Application

    streamlit run app.py

Open browser at:

    http://localhost:8501

---

## ğŸ§ª Example Queries

### Document-based

    Explain retrieval augmented generation

### Web-based

    Latest developments in generative AI

### Hybrid

    How does RAG compare with current AI tools?

---

## ğŸ§  Design Decisions & Tradeoffs

### Why FAISS?

- Fast local vector search  
- No external service dependency  
- Production-proven  

### Why Local Embeddings & LLM?

- Zero API cost  
- Offline capability  
- Easy deployment  
- Architecture remains model-agnostic  

### Why Separate Evidence?

- Prevents hallucinations  
- Improves trust  
- Aligns with enterprise explainability standards  

---

## ğŸ”® Future Improvements

- Replace local LLM with GPT-4 / Claude  
- Add reranking (Cross-Encoders)  
- Persistent document upload in UI  
- User feedback loop  
- Streaming responses

